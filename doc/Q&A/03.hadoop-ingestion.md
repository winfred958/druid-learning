# hadoop ingestion 问题

## 1. "Error: com.google.inject.util.Types.collectionOf

- 原因:
    - jar 冲突
- 解决方案:
    - jobProperties 配置下, 加上 (优先使用用户jar)
        - "mapreduce.job.user.classpath.first": "true"

## 2. TSV数据, hadoop ingestion task , RE: Failure on row[xxxxxxx]

- 原因:
    - 数据解析异常
- 解决方式:
    - 检查 task 配置, 数据分隔符是否制定
        - ```json
          {
          "parseSpec": {
          "dimensionsSpec": {
          "dimensionExclusions": [],
          "dimensions": [
          {
          "type": "string",
          "name": "imp_date"
          },
          {
          "type": "string",
          "name": "video_id"
          },
          {
          "type": "string",
          "name": "account_id"
          },
          {
          "type": "long",
          "name": "play_vv"
          },
          {
          "type": "string",
          "name": "manual_category"
          },
          {
          "type": "string",
          "name": "manual_category_l2"
          },
          {
          "type": "string",
          "name": "video_createtime"
          },
          {
          "type": "string",
          "name": "card_status"
          },
          {
          "type": "string",
          "name": "material_id"
          },
          {
          "type": "string",
          "name": "manual_tags"
          }
          ],
          "spatialDimensions": []
          },
          "delimiter": "|",
          "timestampSpec": {
          "column": "imp_date",
          "format": "yyyyMMddHH"
          },
          "columns": [
          "imp_date",
          "video_id",
          "account_id",
          "play_vv",
          "manual_category",
          "manual_category_l2",
          "video_createtime",
          "card_status",
          "material_id",
          "manual_tags"
          ],
          "format": "tsv"
          },
          "type": "hadoopyString"
          }
          ```

## 3. 读取远端hdfs数据, 配置了双 nameservice, 报错: ava.lang.RuntimeException: java.net.ConnectException: Call From ........

- 原因
    - 远端host 解析问题
- 解决方案:
    - jobProperties 配置下, 使用不使用host
        - "dfs.client.use.datanode.hostname": "false"